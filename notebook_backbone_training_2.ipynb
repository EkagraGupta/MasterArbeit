{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":8073860,"sourceType":"datasetVersion","datasetId":4764421},{"sourceId":9232557,"sourceType":"datasetVersion","datasetId":5584357},{"sourceId":121438,"sourceType":"modelInstanceVersion","modelInstanceId":102186,"modelId":126396}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport random\nimport torch\n\nDATASET_NAME = 'CIFAR10'    # CIFAR10, CIFAR100\nDATASET_TYPE = 'custom'   # baseline, custom\nREWEIGHT = True\nEPOCHS = 200\nBATCH_SIZE = 128\nENABLE_TPU = True\nLEARNING_RATE = 0.1   # 0.15(default), 0.1\nMANUAL_SEED = 1\n\n# CIFAR-10-C\nif DATASET_NAME=='CIFAR10':\n    dataset_dir = '/kaggle/input/cifar-c'\n    print(os.listdir(dataset_dir))\n    # Define the path to the subdirectory\n    sub_dir = os.path.join(dataset_dir, 'CIFAR-10-C')\n    # List contents of the subdirectory\n    print(os.listdir(sub_dir))\nelif DATASET_NAME=='CIFAR100':\n    # CIFAR-100-C\n    dataset_dir = '/kaggle/input/cifar-100-c'\n    print(os.listdir(dataset_dir))\nelse:\n    raise ValueError(f'Dataset {DATASET_NAME} not supported')\n    \n\nprint(f'Hyperparameters:\\n\\tDataset: {DATASET_NAME}\\n\\tType: {DATASET_TYPE}\\n\\tEpochs: {EPOCHS}\\n\\tTPU Enabled: {ENABLE_TPU}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:01:53.094205Z","iopub.execute_input":"2024-12-03T21:01:53.094601Z","iopub.status.idle":"2024-12-03T21:01:56.591936Z","shell.execute_reply.started":"2024-12-03T21:01:53.094553Z","shell.execute_reply":"2024-12-03T21:01:56.590930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchmetrics scikit-image\n!git clone https://github.com/EkagraGupta/MasterArbeit.git","metadata":{"execution":{"iopub.status.busy":"2024-12-03T21:03:08.368291Z","iopub.execute_input":"2024-12-03T21:03:08.368747Z","iopub.status.idle":"2024-12-03T21:03:17.938924Z","shell.execute_reply.started":"2024-12-03T21:03:08.368709Z","shell.execute_reply":"2024-12-03T21:03:17.937730Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \ng = torch.Generator()\ng.manual_seed(MANUAL_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:03:22.708496Z","iopub.execute_input":"2024-12-03T21:03:22.709432Z","iopub.status.idle":"2024-12-03T21:03:22.717324Z","shell.execute_reply.started":"2024-12-03T21:03:22.709371Z","shell.execute_reply":"2024-12-03T21:03:22.716334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import statements\nimport torch\nimport random\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torchvision.transforms import TrivialAugmentWide\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import ConcatDataset\nimport os\n\n# Define the device\ntpu = ENABLE_TPU\n\nif tpu == True:\n    print('TPU is Enabled')\n    import torch_xla\n    import torch_xla.core.xla_model as xm\n    device = xm.xla_device()\nelse:\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  #intend here for else\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, np_images, original_dataset, resize):\n        # Load images\n        self.images = torch.from_numpy(np_images).permute(0, 3, 1, 2) / 255\n         #Normalize the images\n        #transform_test = transforms.Compose([\n            #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        #])\n        #self.images = transform_test(self.images)\n        #if resize == True:\n            #self.images = transforms.Resize(224, antialias=True)(self.images)\n        \n        # Extract labels from the original PyTorch dataset\n        self.labels = [label for _, label in original_dataset]\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, index):\n        # Get image and label for the given index\n        image = self.images[index]\n        label = self.labels[index]\n\n        return image, label\n\n# Define the function to load corrupted datasets separately\ndef load_data_c_separately(dataset, testset, resize, test_transforms, batch_size):\n    corruptions = ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression', 'speckle_noise', 'gaussian_blur', 'spatter', 'saturate']\n    np.asarray(corruptions)\n    c_datasets = {}\n    for corruption in corruptions:\n        if dataset == 'CIFAR10':\n            np_data_c = np.load(f'/kaggle/input/cifar-c/CIFAR-10-C/{corruption}.npy')\n            np_data_c = np.array(np.array_split(np_data_c, 5))\n            custom_dataset = CustomDataset(np_data_c[0], testset, resize)  # Load only one split for now\n            custom_dataloader = torch.utils.data.DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n            c_datasets[corruption] = custom_dataloader\n        else:\n            print('No corrupted benchmark available other than CIFAR10-c.')\n\n    return c_datasets\n\n\n# Load corrupted datasets\n#corrupted_datasets = load_data_c(dataset='CIFAR10', testset=testset, resize=True, \n                                 #test_transforms=None, subset=False, subsetsize=None)\n\n# Transformations for training and test sets\ntransform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32, padding=4),  \n    TrivialAugmentWide(),\n    transforms.ToTensor(),\n])\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n])\n\nbatch_size = BATCH_SIZE\n\nprint(f'Loading {DATASET_NAME}...\\n')\nif DATASET_NAME=='CIFAR10':\n#     Use CIFAR-10 dataset for training\n    num_classes = 10    # CIFAR-10\n    baseline_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                            download=True, transform=transform_train)\n    baseline_trainloader = torch.utils.data.DataLoader(baseline_trainset, batch_size=batch_size,\n                                              shuffle=True, num_workers=2, pin_memory=True, worker_init_fn=seed_worker, generator=g)\n\n    # Use CIFAR-10 dataset for testing\n    baseline_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                           download=True, transform=transform_test)\n    baseline_testloader = torch.utils.data.DataLoader(baseline_testset, batch_size=batch_size,\n                                             shuffle=False, num_workers=2, pin_memory=True, worker_init_fn=seed_worker, generator=g)\nelif DATASET_NAME=='CIFAR100':\n    # # Use CIFAR-100 dataset for training\n    num_classes = 100   # CIFAR-100\n    baseline_trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n                                            download=True, transform=transform_train)\n    baseline_trainloader = torch.utils.data.DataLoader(baseline_trainset, batch_size=batch_size,\n                                              shuffle=True, num_workers=2, pin_memory=True, worker_init_fn=seed_worker, generator=g)\n\n    # Use CIFAR-100 dataset for testing\n    baseline_testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n                                           download=True, transform=transform_test)\n    baseline_testloader = torch.utils.data.DataLoader(baseline_testset, batch_size=batch_size,\n                                             shuffle=False, num_workers=2, pin_memory=True, worker_init_fn=seed_worker, generator=g)\n    \n%cd /kaggle/working/MasterArbeit\n!git checkout add-randomerasing\nfrom augment_dataset import create_transforms, load_data\n# from compute_loss import soft_loss\n\n\"\"\"\n Create the transformations based on the provided flags:\n - If all flags (random_cropping, aggressive_augmentation, and custom) are False:\n   No augmentation other than default preprocessing is applied.\n - If random_cropping (rc) is True and the others (aa and custom) are False:\n   Only random cropping is applied.\n - If random_cropping (rc) and aggressive_augmentation (aa) are True, and custom is False:\n   Random cropping and conventional aggressive augmentation techniques (TA) are applied.\n - If all three flags (rc, aa, custom) are True:\n   Random cropping and soft augmentation techniques (TA) are applied.\n - If random_cropping (rc) is False, aggressive_augmentation (aa) is True, and custom is False:\n   Only conventional aggressive augmentation techniques (TA) are applied (no soft labels).\n - If random_cropping (rc) is False, aggressive_augmentation (aa) is True, and custom is True:\n   Aggressive augmentation (TA) is applied with soft labeling.\n\"\"\"\n\ntransforms_preprocess, transforms_augmentation = create_transforms(random_cropping=False, aggressive_augmentation=False, custom=True, dataset_name=DATASET_NAME)\ncustom_trainset, custom_testset = load_data(transforms_preprocess=transforms_preprocess, transforms_augmentation=transforms_augmentation, dataset_name=DATASET_NAME)\ncustom_trainloader = torch.utils.data.DataLoader(custom_trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, worker_init_fn=seed_worker, generator=g)\ncustom_testloader = torch.utils.data.DataLoader(custom_testset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, worker_init_fn=seed_worker, generator=g)\n%cd\n\nclasses = baseline_trainset.classes\n","metadata":{"execution":{"iopub.status.busy":"2024-12-03T21:03:23.731552Z","iopub.execute_input":"2024-12-03T21:03:23.732000Z","iopub.status.idle":"2024-12-03T21:03:58.243425Z","shell.execute_reply.started":"2024-12-03T21:03:23.731953Z","shell.execute_reply":"2024-12-03T21:03:58.242335Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(transforms_augmentation)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T21:03:58.244913Z","iopub.execute_input":"2024-12-03T21:03:58.245344Z","iopub.status.idle":"2024-12-03T21:03:58.250074Z","shell.execute_reply.started":"2024-12-03T21:03:58.245316Z","shell.execute_reply":"2024-12-03T21:03:58.249084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\ndef imshow(img):\n    npimg = img.cpu().numpy()\n    plt.figure(figsize=(25, 20))  # Adjust the width and height as needed\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\nprint(f'Dataset type \"{DATASET_TYPE}\" displaying...\\n')\n\nif DATASET_TYPE=='custom':\n    dataiter = iter(custom_trainloader)\n    images, labels, confidences = next(dataiter)\n    # print labels \n    if isinstance(confidences, list):\n        # in case we have confidence \n        confidences = confidences[1]\n        \n    print(' '.join(f'{classes[labels[j]]:5s}: {confidences[j].item():.2f}' for j in range(batch_size)))\nelif DATASET_TYPE=='baseline':\n#     if training baseline model\n    dataiter = iter(baseline_trainloader)\n    images, labels = next(dataiter)\n    print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\nelse:\n    raise ValueError(f'Dataset type {DATASET_TYPE} not supported')\n    \n# show images\nimshow(torchvision.utils.make_grid(images))","metadata":{"execution":{"iopub.status.busy":"2024-12-03T21:03:58.251410Z","iopub.execute_input":"2024-12-03T21:03:58.252180Z","iopub.status.idle":"2024-12-03T21:03:59.663857Z","shell.execute_reply.started":"2024-12-03T21:03:58.252151Z","shell.execute_reply":"2024-12-03T21:03:59.662232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define WideResNet 28_4","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nimport numpy as np\n\n\n# Manual implementation of ResNet18\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=num_classes):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Global average pooling layer\n        self.linear = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avgpool(out)  # Apply global average pooling\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\n\n# ResNet18 Architecture\ndef ResNet18(num_classes=num_classes):\n    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T21:03:59.667587Z","iopub.execute_input":"2024-12-03T21:03:59.668163Z","iopub.status.idle":"2024-12-03T21:03:59.690561Z","shell.execute_reply.started":"2024-12-03T21:03:59.668114Z","shell.execute_reply":"2024-12-03T21:03:59.689650Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\ndef conv_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.xavier_uniform(m.weight, gain=np.sqrt(2))\n        init.constant(m.bias, 0)\n    elif classname.find('BatchNorm') != -1:\n        init.constant(m.weight, 1)\n        init.constant(m.bias, 0)\n\nclass WideBasic(nn.Module):\n    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n        super(WideBasic, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n        self.dropout = nn.Dropout(p=dropout_rate)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n            )\n\n    def forward(self, x):\n        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += self.shortcut(x)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion *\n                               planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, widen_factor, dropout_rate=0.3, num_classes=num_classes, factor=1, block=WideBasic):\n        super(WideResNet, self).__init__()\n        self.in_planes = 16\n\n        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n        n = (int)((depth-4)/6)\n        k = widen_factor\n\n        nStages = [16, 16*k, 32*k, 64*k]\n\n        self.conv1 = conv3x3(3,nStages[0], stride=1)\n        self.layer1 = self._wide_layer(block, nStages[1], n, dropout_rate, stride=factor)\n        self.layer2 = self._wide_layer(block, nStages[2], n, dropout_rate, stride=2)\n        self.layer3 = self._wide_layer(block, nStages[3], n, dropout_rate, stride=2)\n        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n        self.linear = nn.Linear(nStages[3], num_classes)\n\n    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n            self.in_planes = planes\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n\n        return out\n\ndef WideResNet_28_4(num_classes, factor=1, block=WideBasic, dropout_rate=0.3):\n    return WideResNet(depth=28, widen_factor=4, dropout_rate=dropout_rate, num_classes=num_classes, factor=factor, block=block)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T21:03:59.691975Z","iopub.execute_input":"2024-12-03T21:03:59.692367Z","iopub.status.idle":"2024-12-03T21:03:59.723134Z","shell.execute_reply.started":"2024-12-03T21:03:59.692321Z","shell.execute_reply":"2024-12-03T21:03:59.721994Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"# Initialize the model\nnet = WideResNet_28_4(num_classes=num_classes)\nnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T21:03:59.724761Z","iopub.execute_input":"2024-12-03T21:03:59.725381Z","iopub.status.idle":"2024-12-03T21:03:59.806251Z","shell.execute_reply.started":"2024-12-03T21:03:59.725311Z","shell.execute_reply":"2024-12-03T21:03:59.805365Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def soft_loss(pred, label, confidence, reweight=False):\n    log_prob = F.log_softmax(pred, dim=1)\n    n_class = pred.size(1)\n\n    # Make soft one-hot target\n    label = label.unsqueeze(1)\n    confidence = confidence.unsqueeze(1).float()\n    # soft one_hot\n    one_hot = torch.ones_like(pred) * (1 - confidence) / (n_class - 1)\n    one_hot.scatter_(dim=1, index=label, src=confidence)\n    \n    # hard one_hot\n#     one_hot = torch.zeros_like(pred)\n#     one_hot.scatter_(dim=1, index=label, value=1.0)\n    # Compute weighted KL loss\n    kl = F.kl_div(input=log_prob, target=one_hot, reduction=\"none\").sum(-1)\n    kl = kl.unsqueeze(1)  # Unweighted\n    if reweight:\n        kl = confidence * kl  # Weighted\n    return kl.mean()","metadata":{"execution":{"iopub.status.busy":"2024-12-03T21:03:59.807462Z","iopub.execute_input":"2024-12-03T21:03:59.808174Z","iopub.status.idle":"2024-12-03T21:03:59.814585Z","shell.execute_reply.started":"2024-12-03T21:03:59.808126Z","shell.execute_reply":"2024-12-03T21:03:59.813840Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport time\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=1e-4)\n\n# Initialize the scheduler\nepochs = EPOCHS\nscheduler = CosineAnnealingLR(optimizer, T_max=epochs)  # Cosine Annealing LR Scheduler\n\n# For plotting\ntrain_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n\n# Training loop\nprint(f'\\nStart Training...\\n')\nfor epoch in range(epochs):  # loop over the dataset multiple times\n    \n    start_time = time.time()\n    \n    running_loss = 0.0\n    total_train = 0\n    correct_train = 0\n    total = 0\n    correct = 0\n    test_loss = 0.0\n    confidences = None\n    \n    net.train()\n    \n    if DATASET_TYPE=='baseline':\n        trainloader = baseline_trainloader\n    elif DATASET_TYPE=='custom':\n        trainloader = custom_trainloader\n    else:\n        raise ValueError('Dataset type is not Valid!')\n    \n    for i, data in enumerate(trainloader):\n            \n        if DATASET_TYPE=='baseline':\n            inputs, labels = data\n        elif DATASET_TYPE=='custom':\n            inputs, labels, confidences = data\n            # get the inputs\n            \"\"\"when the model returns [augmentation_magnitude, confidence_aa], which is the case\n            only when TA with soft labels is applied.\"\"\"\n            if isinstance(confidences, list):\n                confidences = confidences[1]\n            confidences = confidences.to(device)\n        else:\n            raise ValueError('Dataset type is not Valid!')\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n    \n        # Convert labels to one-hot encoded vectors\n        # labels_one_hot = F.one_hot(labels, num_classes=10).float()\n        \n        # forward + backward + optimize\n        outputs = net(inputs)\n        outputs = outputs.to(device)\n        \n        if DATASET_TYPE=='custom':\n            loss = soft_loss(pred=outputs, label=labels, confidence=confidences, reweight=REWEIGHT)\n        else:\n            loss = criterion(outputs, labels)\n        \n        # Check for correct training\n        if np.isnan(loss.detach().cpu().numpy()):\n            raise ValueError('Loss calculation not correct')\n    \n        loss.backward()\n        optimizer.step()\n        \n        if tpu:\n            xm.mark_step()\n        running_loss += loss.item()\n\n        # Calculate training accuracy\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    average_train_loss = running_loss / len(custom_trainloader)\n    train_losses.append(average_train_loss)\n    train_accuracy = correct_train / total_train\n    train_accuracies.append(train_accuracy)\n    \n    with torch.no_grad():\n        net.eval()\n        for images, labels in baseline_testloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            \n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    # calculate and print average loss for current epoch\n    average_test_loss = test_loss / len(custom_testloader)\n    test_losses.append(average_test_loss)\n    test_accuracy = correct / total\n    test_accuracies.append(test_accuracy)\n    \n    print(f'\\nEpoch {epoch + 1} - Train Loss: {average_train_loss:.3f} - Train Accuracy: {100 * train_accuracy: .2f} - Test Loss: {average_test_loss:.3f} - Test Accuracy: {100 * test_accuracy: .2f}')    \n    \n    scheduler.step()\n    end_time = time.time()\n    print(f'\\nProcessing time: {(end_time - start_time): 3f} seconds.')\n\nprint('Finished Training')\n\n# Save the trained model\nPATH = f'/kaggle/working/{DATASET_NAME}_net_ta_{DATASET_TYPE}_{epochs}.pth'\ntorch.save(net.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2024-12-03T21:03:59.815598Z","iopub.execute_input":"2024-12-03T21:03:59.815876Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import csv\n\ncsv_path = f'/kaggle/working/{DATASET_NAME}_training_metrics.csv'\nwith open(csv_path, mode='w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy', 'Test Loss', 'Test Accuracy'])\n    for epoch in range(epochs):\n        writer.writerow([epoch + 1, train_losses[epoch], train_accuracies[epoch], test_losses[epoch], test_accuracies[epoch]])\n\nprint(f'\\nMetrics saved to {csv_path}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.plot(range(1, epochs + 1), train_losses, label='Train Loss', color='tab:red')\nplt.plot(range(1, epochs + 1), test_accuracies, label='Test Accuracy', color='tab:blue')\nplt.xlabel('Epochs')\nplt.ylabel('Value')\nplt.title(f'{DATASET_NAME} - {DATASET_TYPE}')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-03T20:27:40.765118Z","iopub.execute_input":"2024-12-03T20:27:40.765524Z","iopub.status.idle":"2024-12-03T20:27:41.016948Z","shell.execute_reply.started":"2024-12-03T20:27:40.765485Z","shell.execute_reply":"2024-12-03T20:27:41.016104Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluate the model on Testset","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n# Evaluate the CIFAR-10 dataset\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    net.eval()\n    for images, labels in baseline_testloader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    if total == 0:\n        print('No images found for CIFAR-10 dataset.')\n    else:\n        cifar10_accuracy = 100 * correct / total\n        print(f'Accuracy of the network on the CIFAR-10 test dataset: {cifar10_accuracy:.2f} %')\n\nif not tpu:\n    # Clear GPU memory\n    torch.cuda.empty_cache()\n\n    # Clear CPU memory\n    torch.cuda.ipc_collect()\n\n# Define the list of corruptions\ncorruptions = ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', \n               'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', \n               'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression', \n               'speckle_noise', 'gaussian_blur', 'spatter', 'saturate']\n\n# Define the batch size\nbatch_size = 256 \n\n# Create an empty dictionary to store corrupted datasets\ncorrupted_datasets = {}\n\n# Prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# List to store average accuracies for each corruption dataset\naverage_accuracies = []\n\n# Loop over corruptions, loading and testing all 5 severity levels of each corruption dataset\nfor corruption in corruptions:\n    print(f\"Testing on corruption: {corruption}\")\n\n    # Load and test datasets for all 5 severity levels of the current corruption\n    try:\n        if DATASET_NAME=='CIFAR10':\n            np_data_c = np.load(f'/kaggle/input/cifar-c/CIFAR-10-C/{corruption}.npy')\n        elif DATASET_NAME=='CIFAR100':\n            np_data_c = np.load(f'/kaggle/input/cifar-100-c/{corruption}.npy')\n        else:\n            raise ValueError(f'Corruption dataset {DATASET_NAME} not loaded')\n            \n        np_data_c_splits = np.array_split(np_data_c, 5)\n        \n        # List to store accuracies of all severity levels for averaging\n        accuracies = []\n\n        for i, np_data_c_split in enumerate(np_data_c_splits):\n            custom_dataset = CustomDataset(np_data_c_split, baseline_testset, resize=True)\n            custom_dataloader = torch.utils.data.DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n\n            # Testing loop for the current corruption dataset split\n            correct = 0\n            total = 0\n\n            with torch.no_grad():\n                images_loaded = 0  # Counter for images loaded for the current corruption\n                for images, labels in custom_dataloader:\n                    images_loaded += len(images)  # Increment the counter by the number of images loaded\n                    images, labels = images.to(device), labels.to(device)\n                    # Calculate outputs by running images through the network\n                    outputs = net(images)\n                    # The class with the highest energy is chosen as prediction\n                    _, predicted = torch.max(outputs.data, 1)\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n\n                if total == 0:\n                    print(f'No images found for {corruption} dataset split {i+1}.')\n                else:\n                    accuracy = 100 * correct / total\n                    print(f'Accuracy of the network on {corruption} dataset split {i+1}: {accuracy:.2f} %')\n                    accuracies.append(accuracy)\n\n                # Print the number of images loaded for the current corruption dataset split\n                #print(f\"Images loaded for {corruption} dataset split {i+1}: {images_loaded}\")\n                \n                if not tpu:\n                    # Clear GPU memory\n                    torch.cuda.empty_cache()\n                    # Clear CPU memory\n                    torch.cuda.ipc_collect()\n\n                # Delete variables to free up memory\n                del custom_dataset\n                del custom_dataloader\n\n        # Calculate and print the average accuracy for the corruption dataset\n        if accuracies:\n            average_accuracy = sum(accuracies) / len(accuracies)\n            average_accuracies.append(average_accuracy)\n            print(f'Average accuracy for {corruption} dataset: {average_accuracy:.2f} %')\n\n    except FileNotFoundError:\n        print(f'Corruption {corruption} dataset not found.')\n        continue\n\n# Calculate and print the average robust accuracy\nif average_accuracies:\n    average_robust_accuracy = sum(average_accuracies) / len(average_accuracies)\n    print(f'Average Robust Accuracy: {average_robust_accuracy:.2f} %')\nelse:\n    print(\"No corrupt datasets found for evaluation.\")","metadata":{"execution":{"iopub.status.busy":"2024-12-03T20:27:41.019200Z","iopub.execute_input":"2024-12-03T20:27:41.019709Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load the model checkpoint\n# net = WideResNet_28_4(num_classes=num_classes)\n# checkpoint_path = '/kaggle/working/MasterArbeit/models/CIFAR10_net_ta_custom_100.pth'\n# checkpoint = torch.load(checkpoint_path)\n# net.load_state_dict(checkpoint, strict=False)\n# net.to(device)\n\n# import torch\n# import numpy as np\n\n\n# # Evaluate the CIFAR-10 dataset\n# correct = 0\n# total = 0\n\n# with torch.no_grad():\n#     net.eval()\n#     for images, labels in baseline_testloader:\n#         images, labels = images.to(device), labels.to(device)\n#         outputs = net(images)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n\n#     if total == 0:\n#         print('No images found for CIFAR-10 dataset.')\n#     else:\n#         cifar10_accuracy = 100 * correct / total\n#         print(f'Accuracy of the network on the CIFAR-10 test dataset: {cifar10_accuracy:.2f} %')\n        \n# if not tpu:\n#     # Clear GPU memory\n#     torch.cuda.empty_cache()\n\n#     # Clear CPU memory\n#     torch.cuda.ipc_collect()\n\n# # Define the list of corruptions\n# corruptions = ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', \n#                'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', \n#                'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression', \n#                'speckle_noise', 'gaussian_blur', 'spatter', 'saturate']\n\n# # Define the batch size\n# batch_size = 256 \n\n# # Create an empty dictionary to store corrupted datasets\n# corrupted_datasets = {}\n\n# # Prepare to count predictions for each class\n# correct_pred = {classname: 0 for classname in classes}\n# total_pred = {classname: 0 for classname in classes}\n\n# # List to store average accuracies for each corruption dataset\n# average_accuracies = []\n\n# # Loop over corruptions, loading and testing all 5 severity levels of each corruption dataset\n# for corruption in corruptions:\n#     print(f\"Testing on corruption: {corruption}\")\n\n#     # Load and test datasets for all 5 severity levels of the current corruption\n#     try:\n#         if DATASET_NAME=='CIFAR10':\n#             np_data_c = np.load(f'/kaggle/input/cifar-c/CIFAR-10-C/{corruption}.npy')\n#         elif DATASET_NAME=='CIFAR100':\n#             np_data_c = np.load(f'/kaggle/input/cifar-100-c/{corruption}.npy')\n#         else:\n#             raise ValueError(f'Corruption dataset {DATASET_NAME} not loaded')\n#         np_data_c_splits = np.array_split(np_data_c, 5)\n        \n#         # List to store accuracies of all severity levels for averaging\n#         accuracies = []\n\n#         for i, np_data_c_split in enumerate(np_data_c_splits):\n#             custom_dataset = CustomDataset(np_data_c_split, baseline_testset, resize=True)\n#             custom_dataloader = torch.utils.data.DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n\n#             # Testing loop for the current corruption dataset split\n#             correct = 0\n#             total = 0\n\n#             with torch.no_grad():\n#                 images_loaded = 0  # Counter for images loaded for the current corruption\n#                 for images, labels in custom_dataloader:\n#                     images_loaded += len(images)  # Increment the counter by the number of images loaded\n#                     images, labels = images.to(device), labels.to(device)\n#                     # Calculate outputs by running images through the network\n#                     outputs = net(images)\n#                     # The class with the highest energy is chosen as prediction\n#                     _, predicted = torch.max(outputs.data, 1)\n#                     total += labels.size(0)\n#                     correct += (predicted == labels).sum().item()\n\n#                 if total == 0:\n#                     print(f'No images found for {corruption} dataset split {i+1}.')\n#                 else:\n#                     accuracy = 100 * correct / total\n#                     print(f'Accuracy of the network on {corruption} dataset split {i+1}: {accuracy:.2f} %')\n#                     accuracies.append(accuracy)\n\n#                 # Print the number of images loaded for the current corruption dataset split\n#                 #print(f\"Images loaded for {corruption} dataset split {i+1}: {images_loaded}\")\n                \n#                 if not tpu:\n#                     # Clear GPU memory\n#                     torch.cuda.empty_cache()\n#                     # Clear CPU memory\n#                     torch.cuda.ipc_collect()\n\n#                 # Delete variables to free up memory\n#                 del custom_dataset\n#                 del custom_dataloader\n\n#         # Calculate and print the average accuracy for the corruption dataset\n#         if accuracies:\n#             average_accuracy = sum(accuracies) / len(accuracies)\n#             average_accuracies.append(average_accuracy)\n#             print(f'Average accuracy for {corruption} dataset: {average_accuracy:.2f} %')\n\n#     except FileNotFoundError:\n#         print(f'Corruption {corruption} dataset not found.')\n#         continue\n\n# # Calculate and print the average robust accuracy\n# if average_accuracies:\n#     average_robust_accuracy = sum(average_accuracies) / len(average_accuracies)\n#     print(f'Average Robust Accuracy: {average_robust_accuracy:.2f} %')\n# else:\n#     print(\"No corrupt datasets found for evaluation.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}